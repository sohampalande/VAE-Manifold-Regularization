{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "067ca069",
   "metadata": {},
   "source": [
    "# VAE for Time Series Data\n",
    "\n",
    "The purpose of this notebook is to test the developed time series VAE module on real time series datasets. We will go through an example of generating synthetic stock data based on daily price data from the Amazon stock from the years 2010 to 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e8e870",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3820989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from models.tsvae_conv import ConvTimeSeriesVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d97337",
   "metadata": {},
   "source": [
    "## Loading the Datasets\n",
    "\n",
    "In order to train the model, we need to read the csv file containing the data into the Pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71546d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_name = 'AMZN_10-20'\n",
    "file_path = './datasets/' + dataset_name + '.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd6352",
   "metadata": {},
   "source": [
    "## Instantiating the Model\n",
    " \n",
    "Before creating the model, we need to define various parameters. We can roughly categorize the types of parameters into three classes:\n",
    "\n",
    "1. **Model parameters**: These parameters are related to the architecture of the underlying VAE model.  \n",
    "2. **Training parameters**: These parameters are related to the training process of the VAE model when given data. These parameters are standard in machine learning models.\n",
    "3. **Preprocessing parameters**: These parameters are related to the preprocessing required to train a deep generative model on a time series dataset. This also involves two **required** arguments:\n",
    "    - *time_column*: a string with the name of the column in the Pandas dataframe that corresponds to the temporal component. For example, for daily stock data, this corresonds to the date. There can only be a single time column.\n",
    "    - *feature_names*: a list containing the name of the column(s) in the Pandas dataframes that contain the features of the time series. For example, for the daily stock data, features could correspond to the open price and close price.\n",
    "    \n",
    "**Note**: With the exception of \"time_column\" and \"feature_names\", all function arguments in the creation of the model object and the fitting of the model have default parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - All global parameters\n",
    "# -- Model parameters\n",
    "latent_dimension = 8\n",
    "hidden_layers = [50, 100, 200]\n",
    "kernel_size = 3\n",
    "reconstruction_wt = 1\n",
    "# -- Training parameters\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "# -- Preprocessing parameters\n",
    "seq_len = 30\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "time_name = 'Date'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b577d77",
   "metadata": {},
   "source": [
    "With all the above parameters defined, we are now ready to instantiate our VAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model \n",
    "model = ConvTimeSeriesVAE(seq_len=seq_len, dataset=dataset, time_column=time_name, feature_names=features,\n",
    "                          latent_dim=latent_dimension, hidden_layer_sizes=hidden_layers,\n",
    "                          reconstruction_wt=reconstruction_wt, kernel_size=kernel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a13c6",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "After instantiating the model, we can call the fit function to train it according to the defined training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the dataset\n",
    "model.fit(batch_size=batch_size, lr=lr, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32125105",
   "metadata": {},
   "source": [
    "## Generating Samples from the Trained Model\n",
    "\n",
    "Once the model is fit, we can call the sample function to generating synthetic time series segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5445b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_dataset = model.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c7520d",
   "metadata": {},
   "source": [
    "### Format of Synthetic Data\n",
    "\n",
    "By default, the samples are outputted to a Pandas dataframe (which can be saved as a csv file by using the to_csv() method in Pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d6de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83136172",
   "metadata": {},
   "source": [
    "Because the model generates independently sampled segments of the time series, the output format of the synthetic data *must* differ from that the original training dataset. As shown above, in addition to the features of the time series, each row of the outputted Pandas dataframe shows the segment index (which segment that row belongs to) as well as the time index (the corresponding time point of that row for a given segment)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315139c",
   "metadata": {},
   "source": [
    "## Visualization of Synthetic Data\n",
    "\n",
    "Here, we run a simple test to visualize the synthetic data as compared to the original dataset (in terms of segments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f8300",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test to see quality of generated synthetic data\n",
    "N = 50\n",
    "samples = model.sample(N, return_dataframe=False)\n",
    "compare_idx = np.random.choice(model.dataset.shape[0], N, replace=False)\n",
    "for i in range(samples.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.plot(model.dataset[compare_idx, i, :].squeeze().T, c='k', alpha=0.1)\n",
    "    plt.plot(samples[:, i, :].squeeze().T, c='r', alpha=0.3)\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel(features[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba9a598",
   "metadata": {},
   "source": [
    "As we can see, the synthetic segments (in red) resemeble the original dataset segments (in black) across almost all features. Notice that for the volume feature, the synthetic data does not capture the highly nonstationary behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-pavilion",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-carnival",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-transition",
   "metadata": {},
   "source": [
    "We can save the model by calling the save method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'example_model'\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-contact",
   "metadata": {},
   "source": [
    "We can verify that the model has been properly saved by calling the load method into a new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = ConvTimeSeriesVAE(seq_len=seq_len, dataset=dataset, time_column=time_name, feature_names=features,\n",
    "                               latent_dim=latent_dimension, hidden_layer_sizes=hidden_layers,\n",
    "                               reconstruction_wt=reconstruction_wt, kernel_size=kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy.compute_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-broadcast",
   "metadata": {},
   "source": [
    "Before loading the model, the value of the metrics are bad. Using the load method, we can use the pre-trained model and then compute the metrics again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy.compute_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-publicity",
   "metadata": {},
   "source": [
    "We can see that the metrics are improved once the pre-trained model has been loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-owner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_time-series-vae)",
   "language": "python",
   "name": "conda_time-series-vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
